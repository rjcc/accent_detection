{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AccentDetectionResNet_v1",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjcc/accent_detection/blob/master/AccentDetectionResNet_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7kghzERL7LT",
        "colab_type": "text"
      },
      "source": [
        "# 1. Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woHokpL7LzOd",
        "colab_type": "text"
      },
      "source": [
        "Lets import basic libraries required for most tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtRRTYQq4LrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "%matplotlib inline \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JmYIEYxMmsV",
        "colab_type": "text"
      },
      "source": [
        "Lets get the data from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzGq4PBHablZ",
        "colab_type": "code",
        "outputId": "79a015a6-036b-4adb-cf9a-1bcfc363c4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/rjcc/accent_detection.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'accent_detection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUAm4sE_M933",
        "colab_type": "text"
      },
      "source": [
        "Lets install TF 2.0 Beta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41SteSlHjgN1",
        "colab_type": "code",
        "outputId": "b8f2a241-4842-4ca6-d4e7-a3b1117fac9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7fA4-Dojs-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow-gpu==2.0.0-beta0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1vQXt6KNDZH",
        "colab_type": "text"
      },
      "source": [
        "Now we import the necessary modules to build the model.\n",
        "\n",
        "Also do a sanity check on the version and confirm we are running with GPU's"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg0xrL3i491Q",
        "colab_type": "code",
        "outputId": "741f54aa-2753-4fc3-cb15-902e73ecf59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten, Add, BatchNormalization, Input, ZeroPadding2D, AveragePooling2D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau \n",
        "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "from tensorflow.keras.initializers import RandomNormal, glorot_uniform\n",
        "from tensorflow.keras.models import  load_model\n",
        "\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.test.is_gpu_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0XirjYnNXbk",
        "colab_type": "text"
      },
      "source": [
        "Now, lets setup some useful variables used for the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWSPk0sH5O-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notebook version token to associated with generated output\n",
        "NBV = \"ResNet_V1\"\n",
        "\n",
        "# Binary classification we only use one class\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "# Since we are working with colored images, we need to specify 3 channels\n",
        "CHANNELS = 1\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Activation for last Dense layer in Binary classfication\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "\n",
        "# Objective function used for binary classification\n",
        "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
        "\n",
        "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
        "LOSS_METRICS = ['categorical_accuracy'] #sparse_categorical_accuracy\n",
        "\n",
        "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
        "NUM_EPOCHS = 200\n",
        "EARLY_STOP_PATIENCE = 20\n",
        "\n",
        "TRAINING_PATH = \"/content/accent_detection/train/\" \n",
        "TEST_PATH = \"/content/accent_detection/test/predict\"\n",
        "\n",
        "LABELS = \"/content/accent_detection/train_labels.csv\"\n",
        "\n",
        "#TENSORBOARD_LOGS = \"/content/gdrive/My Drive/MalariaDetectionProject/Tensorboard/\"\n",
        "\n",
        "PROJECT_FOLDER= \"/content/accent_detection/\"\n",
        "OUTPUT_FOLDER = \"/content/drive/My Drive/Accent_Detection_Out/\"\n",
        "\n",
        "#image sizes taken from problem description\n",
        "img_width = 173\n",
        "img_height = 128\n",
        "\n",
        "RETRAIN = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9u4lVLiPFso",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVjGI-XhPqJE",
        "colab_type": "text"
      },
      "source": [
        "Define the input shape to feed into our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOX8QSTlZd4-",
        "colab_type": "code",
        "outputId": "75634154-994a-4093-8c16-14e5d0349572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "if  tf.keras.backend.image_data_format() == 'channels_first':\n",
        "    input_shape = (CHANNELS, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, CHANNELS)\n",
        "    \n",
        "\n",
        "print(tf.keras.backend.image_data_format())\n",
        "print(input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "channels_last\n",
            "(173, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgGpKWPXPvC_",
        "colab_type": "text"
      },
      "source": [
        "Lets read the CSV with the file names and respective labels.\n",
        "\n",
        "Infected is modified as one of the functions used below required it to be a string. (flow_from_dataframe()  ?)\n",
        "\n",
        "Filename is also adusted so that the file scan be fectched from the folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nij8tjwa5Qv4",
        "colab_type": "code",
        "outputId": "db5584ed-6b05-48c9-a7d8-aec59e1c1da4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "labels = pd.read_csv(LABELS)\n",
        "labels.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   file_id  accent\n",
              "0    10000       1\n",
              "1    10001       1\n",
              "2    10002       0\n",
              "3    10003       2\n",
              "4    10004       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqGfW9og1Ari",
        "colab_type": "code",
        "outputId": "c2a87526-e898-4266-d3a2-e6c8d2e56fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def replace_label(label):\n",
        "    txt = \"\"\n",
        "    if label == 0 :\n",
        "        txt =\"Canada\"\n",
        "    elif label == 1:\n",
        "        txt = \"India\"\n",
        "    elif label == 2:\n",
        "        txt = \"England\"\n",
        "    \n",
        "    return txt\n",
        "    \n",
        "\n",
        "#labels[\"accent\"] = labels[\"accent\"].map(lambda x: replace_label(x))\n",
        "labels[\"accent\"] = labels[\"accent\"].astype(str)\n",
        "labels[\"file_id\"] = labels[\"file_id\"].map(lambda x: \"./{}.png\".format(x))\n",
        "\n",
        "labels.head() #sanity check"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./10000.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./10001.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./10002.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./10003.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./10004.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       file_id accent\n",
              "0  ./10000.png      1\n",
              "1  ./10001.png      1\n",
              "2  ./10002.png      0\n",
              "3  ./10003.png      2\n",
              "4  ./10004.png      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib9MOw-TQp2V",
        "colab_type": "text"
      },
      "source": [
        "Now lets split the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0pQAHlSSeli",
        "colab_type": "code",
        "outputId": "f3b9ec51-f232-4749-e0fb-d8dd7e955489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "train, val = train_test_split(labels, random_state = 123, test_size=0.25, stratify=labels['accent'])\n",
        "\n",
        "#sanity check\n",
        "train.head() \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>./11187.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2937</th>\n",
              "      <td>./12937.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3861</th>\n",
              "      <td>./13861.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3123</th>\n",
              "      <td>./13123.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2971</th>\n",
              "      <td>./12971.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          file_id accent\n",
              "1187  ./11187.png      2\n",
              "2937  ./12937.png      0\n",
              "3861  ./13861.png      1\n",
              "3123  ./13123.png      1\n",
              "2971  ./12971.png      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnoPRRBfSzwY",
        "colab_type": "code",
        "outputId": "a6e43d7d-bb46-4f96-9d03-f85785154e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "val.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2488</th>\n",
              "      <td>./12488.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1570</th>\n",
              "      <td>./11570.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1411</th>\n",
              "      <td>./11411.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3069</th>\n",
              "      <td>./13069.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4376</th>\n",
              "      <td>./14376.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          file_id accent\n",
              "2488  ./12488.png      1\n",
              "1570  ./11570.png      0\n",
              "1411  ./11411.png      0\n",
              "3069  ./13069.png      1\n",
              "4376  ./14376.png      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w19Gi3JK63Tp",
        "colab_type": "text"
      },
      "source": [
        "Lets sort the dataframes so that the ImageGenerator can correctly map the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnZrJyga7B7I",
        "colab_type": "code",
        "outputId": "192dd9f1-661c-44e3-bb93-449927addfca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "train.sort_values(by=[\"accent\"],inplace=True)\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>./11430.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2511</th>\n",
              "      <td>./12511.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3047</th>\n",
              "      <td>./13047.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3002</th>\n",
              "      <td>./13002.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4151</th>\n",
              "      <td>./14151.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          file_id accent\n",
              "1430  ./11430.png      0\n",
              "2511  ./12511.png      0\n",
              "3047  ./13047.png      0\n",
              "3002  ./13002.png      0\n",
              "4151  ./14151.png      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGHyZx2d8DbH",
        "colab_type": "code",
        "outputId": "e7a0c1a3-5e1a-450e-8c32-24ca857070b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "val.sort_values(by=[\"accent\"],inplace=True)\n",
        "val.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>accent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3242</th>\n",
              "      <td>./13242.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1782</th>\n",
              "      <td>./11782.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1789</th>\n",
              "      <td>./11789.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>./10339.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>./10789.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          file_id accent\n",
              "3242  ./13242.png      0\n",
              "1782  ./11782.png      0\n",
              "1789  ./11789.png      0\n",
              "339   ./10339.png      0\n",
              "789   ./10789.png      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPV9WwbHROlK",
        "colab_type": "text"
      },
      "source": [
        "Let's save the two generated dataframes for posterior analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTenbcSxRpCZ",
        "colab_type": "code",
        "outputId": "01b04db2-3b17-406f-9d73-5b944fa2104f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_split_file= \"train_split.csv\".format(OUTPUT_FOLDER,NBV)\n",
        "val_split_file= \"validation_split.csv\".format(OUTPUT_FOLDER,NBV)\n",
        "\n",
        "print(f\"Saving train split file to {train_split_file}\")\n",
        "train.to_csv(train_split_file,header = True,index = False)\n",
        "\n",
        "print(f\"Saving validation split file to {val_split_file}\")\n",
        "val.to_csv(val_split_file,header=True, index = False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving train split file to /content/drive/My Drive/Accent_Detection_Out/train_split_ResNet_V1.csv\n",
            "Saving validation split file to /content/drive/My Drive/Accent_Detection_Out/validation_split_ResNet_V1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sXNPoIMVnlA",
        "colab_type": "text"
      },
      "source": [
        "As a sanity check, lets observe the distrobution of the labels after the split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6gEFb1XV00W",
        "colab_type": "code",
        "outputId": "d5b29fbf-c674-4f1b-a91b-06fed2ff16c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "source": [
        "filter_canada = labels['accent'] == \"0\"\n",
        "filter_india = labels['accent'] == \"1\"\n",
        "filter_england = labels['accent'] == \"2\"\n",
        "\n",
        "count_canada = labels.where(filter_canada).count()['accent']\n",
        "count_india = labels.where(filter_india).count()['accent']\n",
        "count_england = labels.where(filter_england).count()['accent']\n",
        "\n",
        "train_count_canada = train.where(train['accent'] == \"0\").count()['accent']\n",
        "train_count_india = train.where(train['accent'] == \"1\").count()['accent']\n",
        "train_count_england = train.where(train['accent'] == \"2\").count()['accent']\n",
        "\n",
        "cat = [\"Canada\", \"India\", \"England\"]\n",
        "count = [train_count_canada,train_count_india, train_count_england]\n",
        "plt.bar(cat,count)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Train Canada count:{train_count_canada}; Percentage from original:{ train_count_canada/count_canada }\")\n",
        "print(f\"Train India count:{train_count_india}; Percentage from original:{ train_count_india/count_india }\")\n",
        "print(f\"Train India count:{train_count_england}; Percentage from original:{ train_count_england/count_england }\")\n",
        "\n",
        "val_count_canada = val.where(val['accent'] == \"0\").count()['accent']\n",
        "val_count_india = val.where(val['accent'] == \"1\").count()['accent']\n",
        "val_count_england = val.where(val['accent'] == \"2\").count()['accent']\n",
        "\n",
        "\n",
        "\n",
        "count = [val_count_canada,val_count_india,val_count_england]\n",
        "plt.bar(cat,count)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Validation infected count:{val_count_canada}; Percentage from original:{ val_count_canada/count_canada }\")\n",
        "print(f\"Validation infected count:{val_count_india}; Percentage from original:{ val_count_india/count_india }\")\n",
        "print(f\"Validation infected count:{val_count_england}; Percentage from original:{ val_count_england/count_england }\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndcoAkKROGQCS1CkDQJI6ZQBIUqf+H/SfyKeiPahRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Train Canada count:1125; Percentage from original:0.75\n",
            "Train India count:1125; Percentage from original:0.75\n",
            "Train India count:1125; Percentage from original:0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation infected count:375; Percentage from original:0.25\n",
            "Validation infected count:375; Percentage from original:0.25\n",
            "Validation infected count:375; Percentage from original:0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8XTtEU4aYc-",
        "colab_type": "text"
      },
      "source": [
        "Finally, lets prepare the images to be streamed during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byRARZ0I8BE-",
        "colab_type": "code",
        "outputId": "853e5f89-ba13-4cac-efc3-91841d866ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        #rotation_range= 360,\n",
        "        #shear_range=0.1,\n",
        "        #zoom_range=0.1,\n",
        "        vertical_flip=True,\n",
        "        horizontal_flip=True,\n",
        "        brightness_range =[0.8,1.2])\n",
        "\n",
        "validation_datagen= ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(train, \n",
        "                                                    directory=TRAINING_PATH, \n",
        "                                                    x_col='file_id', \n",
        "                                                    y_col='accent', \n",
        "                                                    target_size=(img_height, img_width), \n",
        "                                                    color_mode='grayscale', \n",
        "                                                    classes=[\"0\",\"1\",\"2\"], \n",
        "                                                    class_mode='categorical', \n",
        "                                                    batch_size=BATCH_SIZE, \n",
        "                                                    shuffle=True,  \n",
        "                                                    save_to_dir=None)\n",
        "    \n",
        "validation_generator = validation_datagen.flow_from_dataframe(val, \n",
        "                                                    directory=TRAINING_PATH, \n",
        "                                                    x_col='file_id', \n",
        "                                                    y_col='accent', \n",
        "                                                    target_size=(img_height, img_width), \n",
        "                                                    color_mode='grayscale', \n",
        "                                                    classes=[\"0\",\"1\",\"2\"], \n",
        "                                                    class_mode='categorical', \n",
        "                                                    batch_size=BATCH_SIZE, \n",
        "                                                    shuffle=True,  \n",
        "                                                    save_to_dir=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3375 validated image filenames belonging to 3 classes.\n",
            "Found 1125 validated image filenames belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JQVQ9BW3uBT",
        "colab_type": "code",
        "outputId": "74035f57-dbe4-407b-e5cb-ffe56c7df1c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_generator.class_indices)\n",
        "print(validation_generator.class_indices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'0': 0, '1': 1, '2': 2}\n",
            "{'0': 0, '1': 1, '2': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpR_lVWOZLXH",
        "colab_type": "code",
        "outputId": "8bc9aaea-8c92-4a87-d14e-83db2e8edcd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "my_image = io.imread('/content/accent_detection/train/10000.png', as_gray=True)\n",
        "\n",
        "# look at the image\n",
        "plt.imshow(my_image)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f24f453c630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neFXeOmLXtwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fllA71qSalgC",
        "colab_type": "text"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2XxyzSt8LiO",
        "colab_type": "code",
        "outputId": "5595cbf0-90e6-4a2c-ee59-dcd5c5d16ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if RETRAIN:\n",
        "    model= load_model(f\"{OUTPUT_FOLDER}CustomNet_{NBV}_best.hdf5\")\n",
        "\n",
        "else:    \n",
        "    base_model = ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,CHANNELS))\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.70)(x)\n",
        "    predictions = Dense(NUM_CLASSES, activation= 'softmax')(x)\n",
        "    model = Model(inputs = base_model.input, outputs = predictions)\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0702 22:20:14.120826 139800166623104 nn_ops.py:4220] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 173, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 134, 179, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 64, 87, 64)   3200        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 64, 87, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 64, 87, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 66, 89, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 44, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 32, 44, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 32, 44, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 44, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 32, 44, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 32, 44, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 44, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 32, 44, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 32, 44, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 32, 44, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 32, 44, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 44, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 44, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 32, 44, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 32, 44, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 44, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 32, 44, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 32, 44, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 44, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 32, 44, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 32, 44, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 44, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 44, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 32, 44, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 32, 44, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 44, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 32, 44, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 32, 44, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 44, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 32, 44, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 32, 44, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 44, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 44, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 16, 22, 128)  32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 16, 22, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 22, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 16, 22, 128)  147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 16, 22, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 22, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 16, 22, 512)  66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 16, 22, 512)  131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 16, 22, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 16, 22, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 22, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 22, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 16, 22, 128)  65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 16, 22, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 22, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 16, 22, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 16, 22, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 22, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 16, 22, 512)  66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 16, 22, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 22, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 22, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 16, 22, 128)  65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 16, 22, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 22, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 16, 22, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 16, 22, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 22, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 16, 22, 512)  66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 16, 22, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 22, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 22, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 16, 22, 128)  65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 16, 22, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 22, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 16, 22, 128)  147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 16, 22, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 22, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 16, 22, 512)  66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 16, 22, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 22, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 22, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 8, 11, 256)   131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 8, 11, 256)   1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 11, 256)   0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 8, 11, 256)   590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 8, 11, 256)   1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 11, 256)   0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 8, 11, 1024)  263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 8, 11, 1024)  525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 8, 11, 1024)  4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 8, 11, 1024)  4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 11, 1024)  0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 11, 1024)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 8, 11, 256)   262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 8, 11, 256)   1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 11, 256)   0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 8, 11, 256)   590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 8, 11, 256)   1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 11, 256)   0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 8, 11, 1024)  263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 8, 11, 1024)  4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 11, 1024)  0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 11, 1024)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 8, 11, 256)   262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 8, 11, 256)   1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 11, 256)   0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 8, 11, 256)   590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 8, 11, 256)   1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 11, 256)   0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 8, 11, 1024)  263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 8, 11, 1024)  4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 11, 1024)  0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 11, 1024)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 8, 11, 256)   262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 8, 11, 256)   1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 11, 256)   0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 8, 11, 256)   590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 8, 11, 256)   1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 11, 256)   0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 8, 11, 1024)  263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 8, 11, 1024)  4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 11, 1024)  0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 11, 1024)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 8, 11, 256)   262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 8, 11, 256)   1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 11, 256)   0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 8, 11, 256)   590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 8, 11, 256)   1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 11, 256)   0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 8, 11, 1024)  263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 8, 11, 1024)  4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 11, 1024)  0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 11, 1024)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 8, 11, 256)   262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 8, 11, 256)   1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 11, 256)   0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 8, 11, 256)   590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 8, 11, 256)   1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 11, 256)   0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 8, 11, 1024)  263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 8, 11, 1024)  4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 11, 1024)  0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 11, 1024)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 4, 6, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 4, 6, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 6, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 4, 6, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 4, 6, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 6, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 4, 6, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 4, 6, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 4, 6, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 4, 6, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 4, 6, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 6, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 4, 6, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 4, 6, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 6, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 4, 6, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 4, 6, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 6, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 4, 6, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 4, 6, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 4, 6, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 6, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 4, 6, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 4, 6, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 6, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 4, 6, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 4, 6, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 6, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 4, 6, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 4, 6, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 4, 6, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 6, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 3)            6147        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,587,587\n",
            "Trainable params: 23,534,467\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uShgewZrbQHv",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AzCJo6l8Sg-",
        "colab_type": "code",
        "outputId": "923a18e1-5dc1-45d2-ed82-3cee30d09487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)\n",
        "\n",
        "if RETRAIN:\n",
        "    cb_checkpointer = ModelCheckpoint(filepath = f\"{OUTPUT_FOLDER}CustomNet_{NBV}_retrained_best.hdf5\", monitor = 'val_categorical_accuracy', save_best_only = True, mode = 'max', verbose= 1)\n",
        "   \n",
        "else:\n",
        "    cb_checkpointer = ModelCheckpoint(filepath = f\"{OUTPUT_FOLDER}CustomNet_{NBV}_best.hdf5\", monitor = 'val_categorical_accuracy', save_best_only = True, mode = 'max', verbose= 1)\n",
        "\n",
        "\n",
        "#logdir=TENSORBOARD_LOGS + \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, update_freq= 'batch', histogram_freq=1)\n",
        "#print(f\"Tensorboard folder:{logdir}\")\n",
        "\n",
        "STEPS_PER_EPOCH_TRAINING = train_generator.n // train_generator.batch_size\n",
        "STEPS_PER_EPOCH_VALIDATION = validation_generator.n // validation_generator.batch_size\n",
        "\n",
        "print(f\"STEPS_PER_EPOCH_TRAINING:{STEPS_PER_EPOCH_TRAINING}; STEPS_PER_EPOCH_VALIDATION: {STEPS_PER_EPOCH_VALIDATION}\")\n",
        "\n",
        "\n",
        "fit_history = model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
        "        epochs = NUM_EPOCHS,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=STEPS_PER_EPOCH_VALIDATION, #callbacks=[cb_checkpointer, cb_early_stopper,tensorboard_callback,reduce_lr\n",
        "        callbacks=[cb_checkpointer])\n",
        "\n",
        "if RETRAIN:\n",
        "    model.load_weights(f\"{OUTPUT_FOLDER}CustomNet_{NBV}_retrained_best.hdf5\")\n",
        "\n",
        "else:\n",
        "    model.load_weights(f\"{OUTPUT_FOLDER}CustomNet_{NBV}_best.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STEPS_PER_EPOCH_TRAINING:105; STEPS_PER_EPOCH_VALIDATION: 35\n",
            "Epoch 1/200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0702 22:20:14.903398 139800166623104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "104/105 [============================>.] - ETA: 0s - loss: 1.8569 - categorical_accuracy: 0.3748\n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.37411, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 80s 761ms/step - loss: 1.8505 - categorical_accuracy: 0.3763 - val_loss: 6.1566 - val_categorical_accuracy: 0.3741\n",
            "Epoch 2/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.6282 - categorical_accuracy: 0.3685\n",
            "Epoch 00002: val_categorical_accuracy did not improve from 0.37411\n",
            "105/105 [==============================] - 27s 255ms/step - loss: 1.6295 - categorical_accuracy: 0.3682 - val_loss: 10.7214 - val_categorical_accuracy: 0.3348\n",
            "Epoch 3/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.4639 - categorical_accuracy: 0.4017\n",
            "Epoch 00003: val_categorical_accuracy did not improve from 0.37411\n",
            "105/105 [==============================] - 27s 254ms/step - loss: 1.4679 - categorical_accuracy: 0.4017 - val_loss: 1.4256 - val_categorical_accuracy: 0.3321\n",
            "Epoch 4/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.4988 - categorical_accuracy: 0.3881\n",
            "Epoch 00004: val_categorical_accuracy did not improve from 0.37411\n",
            "105/105 [==============================] - 27s 253ms/step - loss: 1.4948 - categorical_accuracy: 0.3874 - val_loss: 10.3810 - val_categorical_accuracy: 0.3482\n",
            "Epoch 5/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.3908 - categorical_accuracy: 0.4072\n",
            "Epoch 00005: val_categorical_accuracy did not improve from 0.37411\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 1.3892 - categorical_accuracy: 0.4065 - val_loss: 3.1992 - val_categorical_accuracy: 0.3339\n",
            "Epoch 6/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.4788 - categorical_accuracy: 0.3813\n",
            "Epoch 00006: val_categorical_accuracy did not improve from 0.37411\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 1.4831 - categorical_accuracy: 0.3818 - val_loss: 2.4468 - val_categorical_accuracy: 0.3393\n",
            "Epoch 7/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.3938 - categorical_accuracy: 0.3941\n",
            "Epoch 00007: val_categorical_accuracy did not improve from 0.37411\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 1.3974 - categorical_accuracy: 0.3958 - val_loss: 10.2506 - val_categorical_accuracy: 0.3366\n",
            "Epoch 8/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.2906 - categorical_accuracy: 0.4274\n",
            "Epoch 00008: val_categorical_accuracy improved from 0.37411 to 0.42054, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 30s 286ms/step - loss: 1.2894 - categorical_accuracy: 0.4263 - val_loss: 1.1728 - val_categorical_accuracy: 0.4205\n",
            "Epoch 9/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.2753 - categorical_accuracy: 0.4530\n",
            "Epoch 00009: val_categorical_accuracy did not improve from 0.42054\n",
            "105/105 [==============================] - 27s 257ms/step - loss: 1.2729 - categorical_accuracy: 0.4535 - val_loss: 10.0747 - val_categorical_accuracy: 0.3321\n",
            "Epoch 10/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.2338 - categorical_accuracy: 0.4612\n",
            "Epoch 00010: val_categorical_accuracy improved from 0.42054 to 0.49732, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 30s 289ms/step - loss: 1.2322 - categorical_accuracy: 0.4598 - val_loss: 1.4313 - val_categorical_accuracy: 0.4973\n",
            "Epoch 11/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.1428 - categorical_accuracy: 0.4938\n",
            "Epoch 00011: val_categorical_accuracy did not improve from 0.49732\n",
            "105/105 [==============================] - 27s 257ms/step - loss: 1.1455 - categorical_accuracy: 0.4945 - val_loss: 2.1796 - val_categorical_accuracy: 0.3268\n",
            "Epoch 12/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.2561 - categorical_accuracy: 0.4576\n",
            "Epoch 00012: val_categorical_accuracy did not improve from 0.49732\n",
            "105/105 [==============================] - 27s 253ms/step - loss: 1.2541 - categorical_accuracy: 0.4586 - val_loss: 1.0854 - val_categorical_accuracy: 0.3750\n",
            "Epoch 13/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.2717 - categorical_accuracy: 0.3978\n",
            "Epoch 00013: val_categorical_accuracy did not improve from 0.49732\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 1.2714 - categorical_accuracy: 0.3987 - val_loss: 1.2721 - val_categorical_accuracy: 0.3607\n",
            "Epoch 14/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.2026 - categorical_accuracy: 0.4195\n",
            "Epoch 00014: val_categorical_accuracy did not improve from 0.49732\n",
            "105/105 [==============================] - 27s 253ms/step - loss: 1.2014 - categorical_accuracy: 0.4212 - val_loss: 1.5461 - val_categorical_accuracy: 0.4402\n",
            "Epoch 15/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.1661 - categorical_accuracy: 0.4385\n",
            "Epoch 00015: val_categorical_accuracy did not improve from 0.49732\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 1.1649 - categorical_accuracy: 0.4388 - val_loss: 5.1758 - val_categorical_accuracy: 0.3634\n",
            "Epoch 16/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.1275 - categorical_accuracy: 0.4718\n",
            "Epoch 00016: val_categorical_accuracy improved from 0.49732 to 0.51786, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 30s 287ms/step - loss: 1.1310 - categorical_accuracy: 0.4714 - val_loss: 0.9936 - val_categorical_accuracy: 0.5179\n",
            "Epoch 17/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.1327 - categorical_accuracy: 0.4645\n",
            "Epoch 00017: val_categorical_accuracy did not improve from 0.51786\n",
            "105/105 [==============================] - 27s 254ms/step - loss: 1.1334 - categorical_accuracy: 0.4642 - val_loss: 1.0081 - val_categorical_accuracy: 0.4991\n",
            "Epoch 18/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.0959 - categorical_accuracy: 0.4793\n",
            "Epoch 00018: val_categorical_accuracy did not improve from 0.51786\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 1.0957 - categorical_accuracy: 0.4801 - val_loss: 1.0079 - val_categorical_accuracy: 0.5071\n",
            "Epoch 19/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.0666 - categorical_accuracy: 0.5014\n",
            "Epoch 00019: val_categorical_accuracy did not improve from 0.51786\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 1.0662 - categorical_accuracy: 0.5013 - val_loss: 1.1156 - val_categorical_accuracy: 0.4500\n",
            "Epoch 20/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.0861 - categorical_accuracy: 0.5071\n",
            "Epoch 00020: val_categorical_accuracy improved from 0.51786 to 0.54375, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 31s 291ms/step - loss: 1.0863 - categorical_accuracy: 0.5070 - val_loss: 0.9567 - val_categorical_accuracy: 0.5437\n",
            "Epoch 21/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.1155 - categorical_accuracy: 0.4872\n",
            "Epoch 00021: val_categorical_accuracy did not improve from 0.54375\n",
            "105/105 [==============================] - 27s 257ms/step - loss: 1.1175 - categorical_accuracy: 0.4864 - val_loss: 2.1811 - val_categorical_accuracy: 0.3348\n",
            "Epoch 22/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.0935 - categorical_accuracy: 0.4881\n",
            "Epoch 00022: val_categorical_accuracy did not improve from 0.54375\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 1.0945 - categorical_accuracy: 0.4876 - val_loss: 1.7218 - val_categorical_accuracy: 0.4768\n",
            "Epoch 23/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.0508 - categorical_accuracy: 0.5189\n",
            "Epoch 00023: val_categorical_accuracy did not improve from 0.54375\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 1.0520 - categorical_accuracy: 0.5187 - val_loss: 1.4376 - val_categorical_accuracy: 0.4330\n",
            "Epoch 24/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 1.0149 - categorical_accuracy: 0.5370\n",
            "Epoch 00024: val_categorical_accuracy improved from 0.54375 to 0.57143, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 30s 286ms/step - loss: 1.0128 - categorical_accuracy: 0.5378 - val_loss: 0.9151 - val_categorical_accuracy: 0.5714\n",
            "Epoch 25/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9892 - categorical_accuracy: 0.5517\n",
            "Epoch 00025: val_categorical_accuracy did not improve from 0.57143\n",
            "105/105 [==============================] - 27s 255ms/step - loss: 0.9895 - categorical_accuracy: 0.5506 - val_loss: 0.9051 - val_categorical_accuracy: 0.5714\n",
            "Epoch 26/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9804 - categorical_accuracy: 0.5531\n",
            "Epoch 00026: val_categorical_accuracy did not improve from 0.57143\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.9812 - categorical_accuracy: 0.5523 - val_loss: 2.7512 - val_categorical_accuracy: 0.4357\n",
            "Epoch 27/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9732 - categorical_accuracy: 0.5506\n",
            "Epoch 00027: val_categorical_accuracy did not improve from 0.57143\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.9733 - categorical_accuracy: 0.5513 - val_loss: 1.7265 - val_categorical_accuracy: 0.4545\n",
            "Epoch 28/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9822 - categorical_accuracy: 0.5547\n",
            "Epoch 00028: val_categorical_accuracy did not improve from 0.57143\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.9821 - categorical_accuracy: 0.5560 - val_loss: 2.8298 - val_categorical_accuracy: 0.3768\n",
            "Epoch 29/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9610 - categorical_accuracy: 0.5631\n",
            "Epoch 00029: val_categorical_accuracy improved from 0.57143 to 0.61518, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 32s 302ms/step - loss: 0.9593 - categorical_accuracy: 0.5631 - val_loss: 0.8455 - val_categorical_accuracy: 0.6152\n",
            "Epoch 30/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9213 - categorical_accuracy: 0.5899\n",
            "Epoch 00030: val_categorical_accuracy improved from 0.61518 to 0.62768, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 32s 306ms/step - loss: 0.9222 - categorical_accuracy: 0.5887 - val_loss: 0.8290 - val_categorical_accuracy: 0.6277\n",
            "Epoch 31/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8643 - categorical_accuracy: 0.6124\n",
            "Epoch 00031: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 27s 254ms/step - loss: 0.8643 - categorical_accuracy: 0.6116 - val_loss: 1.0766 - val_categorical_accuracy: 0.5214\n",
            "Epoch 32/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.9127 - categorical_accuracy: 0.6056\n",
            "Epoch 00032: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.9118 - categorical_accuracy: 0.6052 - val_loss: 0.9695 - val_categorical_accuracy: 0.5473\n",
            "Epoch 33/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8588 - categorical_accuracy: 0.6232\n",
            "Epoch 00033: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.8589 - categorical_accuracy: 0.6232 - val_loss: 0.9360 - val_categorical_accuracy: 0.5661\n",
            "Epoch 34/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8269 - categorical_accuracy: 0.6403\n",
            "Epoch 00034: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.8261 - categorical_accuracy: 0.6404 - val_loss: 0.8975 - val_categorical_accuracy: 0.6000\n",
            "Epoch 35/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8140 - categorical_accuracy: 0.6433\n",
            "Epoch 00035: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 27s 253ms/step - loss: 0.8134 - categorical_accuracy: 0.6434 - val_loss: 1.0989 - val_categorical_accuracy: 0.5571\n",
            "Epoch 36/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8110 - categorical_accuracy: 0.6602\n",
            "Epoch 00036: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.8106 - categorical_accuracy: 0.6608 - val_loss: 1.2117 - val_categorical_accuracy: 0.5054\n",
            "Epoch 37/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7793 - categorical_accuracy: 0.6687\n",
            "Epoch 00037: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.7807 - categorical_accuracy: 0.6689 - val_loss: 0.9145 - val_categorical_accuracy: 0.6062\n",
            "Epoch 38/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8039 - categorical_accuracy: 0.6596\n",
            "Epoch 00038: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 27s 253ms/step - loss: 0.8034 - categorical_accuracy: 0.6599 - val_loss: 2.5582 - val_categorical_accuracy: 0.4973\n",
            "Epoch 39/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8772 - categorical_accuracy: 0.6223\n",
            "Epoch 00039: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.8778 - categorical_accuracy: 0.6229 - val_loss: 1.5109 - val_categorical_accuracy: 0.4500\n",
            "Epoch 40/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8943 - categorical_accuracy: 0.6138\n",
            "Epoch 00040: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.8964 - categorical_accuracy: 0.6127 - val_loss: 0.9546 - val_categorical_accuracy: 0.5723\n",
            "Epoch 41/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.8162 - categorical_accuracy: 0.6563\n",
            "Epoch 00041: val_categorical_accuracy did not improve from 0.62768\n",
            "105/105 [==============================] - 26s 249ms/step - loss: 0.8194 - categorical_accuracy: 0.6554 - val_loss: 0.9582 - val_categorical_accuracy: 0.5518\n",
            "Epoch 42/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7826 - categorical_accuracy: 0.6641\n",
            "Epoch 00042: val_categorical_accuracy improved from 0.62768 to 0.62946, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 30s 287ms/step - loss: 0.7829 - categorical_accuracy: 0.6646 - val_loss: 0.8658 - val_categorical_accuracy: 0.6295\n",
            "Epoch 43/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7619 - categorical_accuracy: 0.6805\n",
            "Epoch 00043: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 27s 256ms/step - loss: 0.7625 - categorical_accuracy: 0.6802 - val_loss: 3.6378 - val_categorical_accuracy: 0.4527\n",
            "Epoch 44/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7391 - categorical_accuracy: 0.6964\n",
            "Epoch 00044: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.7393 - categorical_accuracy: 0.6954 - val_loss: 0.9848 - val_categorical_accuracy: 0.5938\n",
            "Epoch 45/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7268 - categorical_accuracy: 0.7007\n",
            "Epoch 00045: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.7254 - categorical_accuracy: 0.7015 - val_loss: 1.3033 - val_categorical_accuracy: 0.5839\n",
            "Epoch 46/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.7242 - categorical_accuracy: 0.7067\n",
            "Epoch 00046: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.7242 - categorical_accuracy: 0.7071 - val_loss: 0.9084 - val_categorical_accuracy: 0.6000\n",
            "Epoch 47/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6696 - categorical_accuracy: 0.7301\n",
            "Epoch 00047: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.6696 - categorical_accuracy: 0.7297 - val_loss: 3.6755 - val_categorical_accuracy: 0.4071\n",
            "Epoch 48/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6688 - categorical_accuracy: 0.7263\n",
            "Epoch 00048: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.6690 - categorical_accuracy: 0.7265 - val_loss: 4.2725 - val_categorical_accuracy: 0.4259\n",
            "Epoch 49/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6656 - categorical_accuracy: 0.7404\n",
            "Epoch 00049: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 248ms/step - loss: 0.6656 - categorical_accuracy: 0.7405 - val_loss: 1.0534 - val_categorical_accuracy: 0.5688\n",
            "Epoch 50/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6251 - categorical_accuracy: 0.7581\n",
            "Epoch 00050: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.6233 - categorical_accuracy: 0.7589 - val_loss: 0.8556 - val_categorical_accuracy: 0.6196\n",
            "Epoch 51/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5858 - categorical_accuracy: 0.7656\n",
            "Epoch 00051: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 248ms/step - loss: 0.5874 - categorical_accuracy: 0.7658 - val_loss: 1.0002 - val_categorical_accuracy: 0.6277\n",
            "Epoch 52/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5840 - categorical_accuracy: 0.7566\n",
            "Epoch 00052: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 249ms/step - loss: 0.5823 - categorical_accuracy: 0.7571 - val_loss: 1.0703 - val_categorical_accuracy: 0.5893\n",
            "Epoch 53/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6104 - categorical_accuracy: 0.7644\n",
            "Epoch 00053: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.6101 - categorical_accuracy: 0.7649 - val_loss: 1.2471 - val_categorical_accuracy: 0.5268\n",
            "Epoch 54/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5626 - categorical_accuracy: 0.7747\n",
            "Epoch 00054: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 27s 253ms/step - loss: 0.5611 - categorical_accuracy: 0.7754 - val_loss: 1.0216 - val_categorical_accuracy: 0.6161\n",
            "Epoch 55/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.6394 - categorical_accuracy: 0.7430\n",
            "Epoch 00055: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.6404 - categorical_accuracy: 0.7418 - val_loss: 1.8558 - val_categorical_accuracy: 0.5991\n",
            "Epoch 56/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5866 - categorical_accuracy: 0.7747\n",
            "Epoch 00056: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 248ms/step - loss: 0.5861 - categorical_accuracy: 0.7754 - val_loss: 1.1834 - val_categorical_accuracy: 0.5420\n",
            "Epoch 57/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5389 - categorical_accuracy: 0.7858\n",
            "Epoch 00057: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.5380 - categorical_accuracy: 0.7860 - val_loss: 1.0476 - val_categorical_accuracy: 0.6089\n",
            "Epoch 58/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5267 - categorical_accuracy: 0.7933\n",
            "Epoch 00058: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 248ms/step - loss: 0.5246 - categorical_accuracy: 0.7940 - val_loss: 1.0920 - val_categorical_accuracy: 0.5875\n",
            "Epoch 59/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5195 - categorical_accuracy: 0.8017\n",
            "Epoch 00059: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.5198 - categorical_accuracy: 0.8018 - val_loss: 1.1112 - val_categorical_accuracy: 0.6080\n",
            "Epoch 60/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5313 - categorical_accuracy: 0.7992\n",
            "Epoch 00060: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.5321 - categorical_accuracy: 0.7993 - val_loss: 1.1828 - val_categorical_accuracy: 0.5714\n",
            "Epoch 61/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.4569 - categorical_accuracy: 0.8194\n",
            "Epoch 00061: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.4582 - categorical_accuracy: 0.8184 - val_loss: 1.0860 - val_categorical_accuracy: 0.6161\n",
            "Epoch 62/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.5174 - categorical_accuracy: 0.7996\n",
            "Epoch 00062: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.5176 - categorical_accuracy: 0.7995 - val_loss: 1.1501 - val_categorical_accuracy: 0.5786\n",
            "Epoch 63/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.4149 - categorical_accuracy: 0.8431\n",
            "Epoch 00063: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.4151 - categorical_accuracy: 0.8426 - val_loss: 1.0138 - val_categorical_accuracy: 0.6286\n",
            "Epoch 64/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.4087 - categorical_accuracy: 0.8512\n",
            "Epoch 00064: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.4147 - categorical_accuracy: 0.8500 - val_loss: 1.2918 - val_categorical_accuracy: 0.5929\n",
            "Epoch 65/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3976 - categorical_accuracy: 0.8486\n",
            "Epoch 00065: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.3967 - categorical_accuracy: 0.8488 - val_loss: 1.2602 - val_categorical_accuracy: 0.5991\n",
            "Epoch 66/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.4214 - categorical_accuracy: 0.8403\n",
            "Epoch 00066: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.4197 - categorical_accuracy: 0.8410 - val_loss: 1.1397 - val_categorical_accuracy: 0.6071\n",
            "Epoch 67/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3794 - categorical_accuracy: 0.8576\n",
            "Epoch 00067: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 249ms/step - loss: 0.3786 - categorical_accuracy: 0.8577 - val_loss: 3.2304 - val_categorical_accuracy: 0.3616\n",
            "Epoch 68/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.4791 - categorical_accuracy: 0.8285\n",
            "Epoch 00068: val_categorical_accuracy did not improve from 0.62946\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.4803 - categorical_accuracy: 0.8280 - val_loss: 1.2501 - val_categorical_accuracy: 0.6259\n",
            "Epoch 69/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3351 - categorical_accuracy: 0.8825\n",
            "Epoch 00069: val_categorical_accuracy improved from 0.62946 to 0.64643, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 31s 294ms/step - loss: 0.3347 - categorical_accuracy: 0.8827 - val_loss: 1.1153 - val_categorical_accuracy: 0.6464\n",
            "Epoch 70/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3163 - categorical_accuracy: 0.8843\n",
            "Epoch 00070: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 27s 253ms/step - loss: 0.3156 - categorical_accuracy: 0.8845 - val_loss: 1.1250 - val_categorical_accuracy: 0.6134\n",
            "Epoch 71/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3199 - categorical_accuracy: 0.8834\n",
            "Epoch 00071: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.3193 - categorical_accuracy: 0.8833 - val_loss: 1.2208 - val_categorical_accuracy: 0.6384\n",
            "Epoch 72/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3792 - categorical_accuracy: 0.8707\n",
            "Epoch 00072: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 249ms/step - loss: 0.3838 - categorical_accuracy: 0.8686 - val_loss: 1.4081 - val_categorical_accuracy: 0.5464\n",
            "Epoch 73/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3259 - categorical_accuracy: 0.8714\n",
            "Epoch 00073: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.3254 - categorical_accuracy: 0.8717 - val_loss: 6.0077 - val_categorical_accuracy: 0.4366\n",
            "Epoch 74/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3046 - categorical_accuracy: 0.8937\n",
            "Epoch 00074: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.3034 - categorical_accuracy: 0.8941 - val_loss: 6.5838 - val_categorical_accuracy: 0.3589\n",
            "Epoch 75/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3334 - categorical_accuracy: 0.8849\n",
            "Epoch 00075: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 27s 252ms/step - loss: 0.3332 - categorical_accuracy: 0.8848 - val_loss: 1.7270 - val_categorical_accuracy: 0.5571\n",
            "Epoch 76/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2593 - categorical_accuracy: 0.9006\n",
            "Epoch 00076: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.2591 - categorical_accuracy: 0.9007 - val_loss: 1.1796 - val_categorical_accuracy: 0.6384\n",
            "Epoch 77/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2862 - categorical_accuracy: 0.9012\n",
            "Epoch 00077: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.2850 - categorical_accuracy: 0.9019 - val_loss: 2.1425 - val_categorical_accuracy: 0.5241\n",
            "Epoch 78/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3840 - categorical_accuracy: 0.8698\n",
            "Epoch 00078: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.3824 - categorical_accuracy: 0.8702 - val_loss: 3.5243 - val_categorical_accuracy: 0.4830\n",
            "Epoch 79/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2529 - categorical_accuracy: 0.9046\n",
            "Epoch 00079: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 247ms/step - loss: 0.2543 - categorical_accuracy: 0.9034 - val_loss: 2.7520 - val_categorical_accuracy: 0.5071\n",
            "Epoch 80/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2190 - categorical_accuracy: 0.9191\n",
            "Epoch 00080: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 249ms/step - loss: 0.2201 - categorical_accuracy: 0.9186 - val_loss: 1.5531 - val_categorical_accuracy: 0.6429\n",
            "Epoch 81/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2437 - categorical_accuracy: 0.9129\n",
            "Epoch 00081: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 247ms/step - loss: 0.2418 - categorical_accuracy: 0.9137 - val_loss: 1.3834 - val_categorical_accuracy: 0.6384\n",
            "Epoch 82/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2340 - categorical_accuracy: 0.9203\n",
            "Epoch 00082: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.2360 - categorical_accuracy: 0.9201 - val_loss: 1.3306 - val_categorical_accuracy: 0.6125\n",
            "Epoch 83/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2388 - categorical_accuracy: 0.9168\n",
            "Epoch 00083: val_categorical_accuracy did not improve from 0.64643\n",
            "105/105 [==============================] - 26s 249ms/step - loss: 0.2385 - categorical_accuracy: 0.9170 - val_loss: 1.2227 - val_categorical_accuracy: 0.6223\n",
            "Epoch 84/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2487 - categorical_accuracy: 0.9139\n",
            "Epoch 00084: val_categorical_accuracy improved from 0.64643 to 0.65357, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 31s 292ms/step - loss: 0.2492 - categorical_accuracy: 0.9133 - val_loss: 1.3138 - val_categorical_accuracy: 0.6536\n",
            "Epoch 85/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2453 - categorical_accuracy: 0.9126\n",
            "Epoch 00085: val_categorical_accuracy did not improve from 0.65357\n",
            "105/105 [==============================] - 27s 254ms/step - loss: 0.2466 - categorical_accuracy: 0.9119 - val_loss: 4.2456 - val_categorical_accuracy: 0.5170\n",
            "Epoch 86/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1620 - categorical_accuracy: 0.9429\n",
            "Epoch 00086: val_categorical_accuracy did not improve from 0.65357\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.1609 - categorical_accuracy: 0.9435 - val_loss: 1.3641 - val_categorical_accuracy: 0.6518\n",
            "Epoch 87/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2697 - categorical_accuracy: 0.9097\n",
            "Epoch 00087: val_categorical_accuracy did not improve from 0.65357\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.2701 - categorical_accuracy: 0.9091 - val_loss: 1.4971 - val_categorical_accuracy: 0.5946\n",
            "Epoch 88/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2216 - categorical_accuracy: 0.9227\n",
            "Epoch 00088: val_categorical_accuracy did not improve from 0.65357\n",
            "105/105 [==============================] - 26s 249ms/step - loss: 0.2198 - categorical_accuracy: 0.9234 - val_loss: 1.4150 - val_categorical_accuracy: 0.6491\n",
            "Epoch 89/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1969 - categorical_accuracy: 0.9293\n",
            "Epoch 00089: val_categorical_accuracy did not improve from 0.65357\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.2035 - categorical_accuracy: 0.9287 - val_loss: 1.3707 - val_categorical_accuracy: 0.6295\n",
            "Epoch 90/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2191 - categorical_accuracy: 0.9225\n",
            "Epoch 00090: val_categorical_accuracy improved from 0.65357 to 0.65893, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 30s 286ms/step - loss: 0.2174 - categorical_accuracy: 0.9232 - val_loss: 1.1826 - val_categorical_accuracy: 0.6589\n",
            "Epoch 91/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1570 - categorical_accuracy: 0.9396\n",
            "Epoch 00091: val_categorical_accuracy did not improve from 0.65893\n",
            "105/105 [==============================] - 27s 254ms/step - loss: 0.1561 - categorical_accuracy: 0.9402 - val_loss: 1.7052 - val_categorical_accuracy: 0.6393\n",
            "Epoch 92/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1539 - categorical_accuracy: 0.9474\n",
            "Epoch 00092: val_categorical_accuracy did not improve from 0.65893\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.1546 - categorical_accuracy: 0.9471 - val_loss: 2.2595 - val_categorical_accuracy: 0.6250\n",
            "Epoch 93/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1233 - categorical_accuracy: 0.9553\n",
            "Epoch 00093: val_categorical_accuracy improved from 0.65893 to 0.67768, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 34s 321ms/step - loss: 0.1231 - categorical_accuracy: 0.9554 - val_loss: 1.3647 - val_categorical_accuracy: 0.6777\n",
            "Epoch 94/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.9541\n",
            "Epoch 00094: val_categorical_accuracy did not improve from 0.67768\n",
            "105/105 [==============================] - 27s 254ms/step - loss: 0.1334 - categorical_accuracy: 0.9542 - val_loss: 1.5636 - val_categorical_accuracy: 0.6679\n",
            "Epoch 95/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1676 - categorical_accuracy: 0.9423\n",
            "Epoch 00095: val_categorical_accuracy did not improve from 0.67768\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.1668 - categorical_accuracy: 0.9426 - val_loss: 1.4035 - val_categorical_accuracy: 0.6268\n",
            "Epoch 96/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1410 - categorical_accuracy: 0.9490\n",
            "Epoch 00096: val_categorical_accuracy did not improve from 0.67768\n",
            "105/105 [==============================] - 26s 249ms/step - loss: 0.1405 - categorical_accuracy: 0.9488 - val_loss: 1.6383 - val_categorical_accuracy: 0.6446\n",
            "Epoch 97/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1286 - categorical_accuracy: 0.9511\n",
            "Epoch 00097: val_categorical_accuracy did not improve from 0.67768\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.1296 - categorical_accuracy: 0.9509 - val_loss: 1.7076 - val_categorical_accuracy: 0.6482\n",
            "Epoch 98/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1550 - categorical_accuracy: 0.9444\n",
            "Epoch 00098: val_categorical_accuracy did not improve from 0.67768\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.1545 - categorical_accuracy: 0.9444 - val_loss: 1.3865 - val_categorical_accuracy: 0.6580\n",
            "Epoch 99/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1150 - categorical_accuracy: 0.9568\n",
            "Epoch 00099: val_categorical_accuracy improved from 0.67768 to 0.69375, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 31s 299ms/step - loss: 0.1145 - categorical_accuracy: 0.9566 - val_loss: 1.3008 - val_categorical_accuracy: 0.6938\n",
            "Epoch 100/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1256 - categorical_accuracy: 0.9589\n",
            "Epoch 00100: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 27s 255ms/step - loss: 0.1247 - categorical_accuracy: 0.9590 - val_loss: 1.7692 - val_categorical_accuracy: 0.6518\n",
            "Epoch 101/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1381 - categorical_accuracy: 0.9517\n",
            "Epoch 00101: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.1377 - categorical_accuracy: 0.9518 - val_loss: 1.4329 - val_categorical_accuracy: 0.6500\n",
            "Epoch 102/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1489 - categorical_accuracy: 0.9462\n",
            "Epoch 00102: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.1493 - categorical_accuracy: 0.9459 - val_loss: 2.6998 - val_categorical_accuracy: 0.5509\n",
            "Epoch 103/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2388 - categorical_accuracy: 0.9133\n",
            "Epoch 00103: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.2378 - categorical_accuracy: 0.9138 - val_loss: 1.9365 - val_categorical_accuracy: 0.6571\n",
            "Epoch 104/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1720 - categorical_accuracy: 0.9402\n",
            "Epoch 00104: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 27s 256ms/step - loss: 0.1759 - categorical_accuracy: 0.9390 - val_loss: 2.1578 - val_categorical_accuracy: 0.6062\n",
            "Epoch 105/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1748 - categorical_accuracy: 0.9366\n",
            "Epoch 00105: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.1736 - categorical_accuracy: 0.9372 - val_loss: 2.5069 - val_categorical_accuracy: 0.6259\n",
            "Epoch 106/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1376 - categorical_accuracy: 0.9544\n",
            "Epoch 00106: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 27s 254ms/step - loss: 0.1372 - categorical_accuracy: 0.9542 - val_loss: 1.5348 - val_categorical_accuracy: 0.6527\n",
            "Epoch 107/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1060 - categorical_accuracy: 0.9635\n",
            "Epoch 00107: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.1064 - categorical_accuracy: 0.9632 - val_loss: 1.6970 - val_categorical_accuracy: 0.6652\n",
            "Epoch 108/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1313 - categorical_accuracy: 0.9552\n",
            "Epoch 00108: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.1332 - categorical_accuracy: 0.9554 - val_loss: 2.3657 - val_categorical_accuracy: 0.5938\n",
            "Epoch 109/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1034 - categorical_accuracy: 0.9611\n",
            "Epoch 00109: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.1030 - categorical_accuracy: 0.9612 - val_loss: 1.4899 - val_categorical_accuracy: 0.6554\n",
            "Epoch 110/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1058 - categorical_accuracy: 0.9619\n",
            "Epoch 00110: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 27s 255ms/step - loss: 0.1049 - categorical_accuracy: 0.9623 - val_loss: 1.3876 - val_categorical_accuracy: 0.6509\n",
            "Epoch 111/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.0951 - categorical_accuracy: 0.9662\n",
            "Epoch 00111: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 27s 254ms/step - loss: 0.0956 - categorical_accuracy: 0.9659 - val_loss: 1.7622 - val_categorical_accuracy: 0.6375\n",
            "Epoch 112/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1288 - categorical_accuracy: 0.9561\n",
            "Epoch 00112: val_categorical_accuracy did not improve from 0.69375\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.1281 - categorical_accuracy: 0.9563 - val_loss: 2.0893 - val_categorical_accuracy: 0.6384\n",
            "Epoch 113/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1063 - categorical_accuracy: 0.9639\n",
            "Epoch 00113: val_categorical_accuracy improved from 0.69375 to 0.70357, saving model to /content/drive/My Drive/Accent_Detection_Out/CustomNet_ResNet_V1_best.hdf5\n",
            "105/105 [==============================] - 31s 292ms/step - loss: 0.1063 - categorical_accuracy: 0.9636 - val_loss: 1.6196 - val_categorical_accuracy: 0.7036\n",
            "Epoch 114/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1280 - categorical_accuracy: 0.9537\n",
            "Epoch 00114: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 27s 254ms/step - loss: 0.1276 - categorical_accuracy: 0.9539 - val_loss: 1.4452 - val_categorical_accuracy: 0.6929\n",
            "Epoch 115/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1096 - categorical_accuracy: 0.9648\n",
            "Epoch 00115: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 27s 253ms/step - loss: 0.1091 - categorical_accuracy: 0.9648 - val_loss: 1.7567 - val_categorical_accuracy: 0.6313\n",
            "Epoch 116/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.0872 - categorical_accuracy: 0.9712\n",
            "Epoch 00116: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.0868 - categorical_accuracy: 0.9714 - val_loss: 2.3947 - val_categorical_accuracy: 0.6179\n",
            "Epoch 117/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.3691 - categorical_accuracy: 0.8913\n",
            "Epoch 00117: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 249ms/step - loss: 0.3704 - categorical_accuracy: 0.8915 - val_loss: 2.1488 - val_categorical_accuracy: 0.5545\n",
            "Epoch 118/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.2589 - categorical_accuracy: 0.9114\n",
            "Epoch 00118: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 252ms/step - loss: 0.2581 - categorical_accuracy: 0.9116 - val_loss: 2.0640 - val_categorical_accuracy: 0.5768\n",
            "Epoch 119/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1638 - categorical_accuracy: 0.9490\n",
            "Epoch 00119: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.1660 - categorical_accuracy: 0.9480 - val_loss: 1.6388 - val_categorical_accuracy: 0.6455\n",
            "Epoch 120/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1396 - categorical_accuracy: 0.9514\n",
            "Epoch 00120: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.1398 - categorical_accuracy: 0.9515 - val_loss: 1.9147 - val_categorical_accuracy: 0.6420\n",
            "Epoch 121/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1279 - categorical_accuracy: 0.9526\n",
            "Epoch 00121: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 27s 253ms/step - loss: 0.1284 - categorical_accuracy: 0.9521 - val_loss: 1.4850 - val_categorical_accuracy: 0.6429\n",
            "Epoch 122/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1323 - categorical_accuracy: 0.9583\n",
            "Epoch 00122: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.1321 - categorical_accuracy: 0.9581 - val_loss: 2.5700 - val_categorical_accuracy: 0.5821\n",
            "Epoch 123/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.0985 - categorical_accuracy: 0.9635\n",
            "Epoch 00123: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.0976 - categorical_accuracy: 0.9638 - val_loss: 1.9895 - val_categorical_accuracy: 0.6339\n",
            "Epoch 124/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1070 - categorical_accuracy: 0.9650\n",
            "Epoch 00124: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.1083 - categorical_accuracy: 0.9644 - val_loss: 2.4956 - val_categorical_accuracy: 0.6027\n",
            "Epoch 125/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1316 - categorical_accuracy: 0.9573\n",
            "Epoch 00125: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 251ms/step - loss: 0.1312 - categorical_accuracy: 0.9574 - val_loss: 2.3168 - val_categorical_accuracy: 0.6321\n",
            "Epoch 126/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1112 - categorical_accuracy: 0.9641\n",
            "Epoch 00126: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.1102 - categorical_accuracy: 0.9644 - val_loss: 1.4522 - val_categorical_accuracy: 0.6830\n",
            "Epoch 127/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.0640 - categorical_accuracy: 0.9780\n",
            "Epoch 00127: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.0642 - categorical_accuracy: 0.9779 - val_loss: 1.6874 - val_categorical_accuracy: 0.6866\n",
            "Epoch 128/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.0667 - categorical_accuracy: 0.9763\n",
            "Epoch 00128: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.0661 - categorical_accuracy: 0.9765 - val_loss: 1.6437 - val_categorical_accuracy: 0.6616\n",
            "Epoch 129/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.0836 - categorical_accuracy: 0.9739\n",
            "Epoch 00129: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 250ms/step - loss: 0.0831 - categorical_accuracy: 0.9741 - val_loss: 1.6563 - val_categorical_accuracy: 0.6732\n",
            "Epoch 130/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.1125 - categorical_accuracy: 0.9687\n",
            "Epoch 00130: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 26s 245ms/step - loss: 0.1123 - categorical_accuracy: 0.9684 - val_loss: 1.5432 - val_categorical_accuracy: 0.6652\n",
            "Epoch 131/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.0786 - categorical_accuracy: 0.9760\n",
            "Epoch 00131: val_categorical_accuracy did not improve from 0.70357\n",
            "105/105 [==============================] - 27s 255ms/step - loss: 0.0779 - categorical_accuracy: 0.9762 - val_loss: 1.5651 - val_categorical_accuracy: 0.6804\n",
            "Epoch 132/200\n",
            "104/105 [============================>.] - ETA: 0s - loss: 0.0653 - categorical_accuracy: 0.9769"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS9NSlr4bGUM",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfNPEoJNba72",
        "colab_type": "text"
      },
      "source": [
        "Let's plot the traininng progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z0NiT9-DHdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(fit_history.history['sparse_categorical_accuracy'])\n",
        "plt.plot(fit_history.history['val_sparse_categorical_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(fit_history.history['loss'])\n",
        "plt.plot(fit_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cenbFnjKbeue",
        "colab_type": "text"
      },
      "source": [
        "Lets also try to use Tensorboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ff_5gP1bpmt",
        "colab_type": "text"
      },
      "source": [
        "# Review the model accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55LjSQ84b4Xa",
        "colab_type": "text"
      },
      "source": [
        "To do this we will use scikit learn to review some of the binary classification metrics.\n",
        "\n",
        "We will do a prediction over the validation data set and we will then compare the ground thruth with the predicted probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_VFBAB_g26o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: read the validation split file\n",
        "df = pd.read_csv(val_split_file)\n",
        "df.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZNf8EWDko6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: perform necessary adjustments to the dataframe\n",
        "#df[\"infected\"] = df[\"infected\"].map(lambda x: \"1\" if x == \"infected\" else \"0\")\n",
        "df[\"file_id\"] = df[\"file_id\"].map(lambda x: x[2:] )\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja_zq_BtlopN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TODO: Add a column to store the prediction value\n",
        "def predict_val_prob(filename):\n",
        "    \n",
        "    file_path = os.path.join(TRAINING_PATH,filename)\n",
        "    img = load_img(file_path, color_mode='grayscale', target_size=(img_height,img_width) )\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    img_array = img_array * (1./255) #scaling the data\n",
        "    dim_array= np.array([img_array]) #tranforming to 4D array required as input\n",
        "    \n",
        "    prediction = model.predict(dim_array, verbose = 0)\n",
        "    \n",
        "    return np.argmax(prediction[0])\n",
        "\n",
        "# TODO: Iterate over each file in df and perform the prediction using the model. update the prediction column wiht the value\n",
        "\n",
        "df[\"predicted\"] = df[\"file_id\"].map(lambda x: predict_val_prob(x) )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlLyltk6or3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_results= df[df.accent == df.predicted]\n",
        "count_accurate = correct_results.count()[\"file_id\"]\n",
        "total_count = df.count()[\"file_id\"]\n",
        "print(f\"correct results percentage: {count_accurate/total_count}\")\n",
        "correct_results.head()\n",
        "# TODO: Add a column to transform the probabilty into the actual class ( 1= infected, 0= not infected)\n",
        "# TODO: Use sklearn functions for auc, confusion matrix, precision and recall, etc\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-Q5nPzOqWoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.metrics import log_loss\n",
        "\n",
        "#log_loss(df[\"infected\"],df[\"predicted\"])\n",
        "\n",
        "# TODO: Use the same log loss formula as in the case description to calculate the log loss of the predicted values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br3GWxhh7ZqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#simple model test\n",
        "file_path =\"/content/accent_detection/train/13242.png\"\n",
        "\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "\n",
        "\n",
        "#img = io.imread(file_path, as_gray=True)\n",
        "#print(f\"Processing file {file_path} ...\")\n",
        "img = load_img(file_path, color_mode='grayscale', target_size=(img_height,img_width) )\n",
        "img_array = img_to_array(img)\n",
        "print(img_array.shape)\n",
        "img_array = img_array * (1./255) #scaling the data\n",
        "dim_array= np.array([img_array]) #tranforming to 4D array required as input\n",
        "\n",
        "prediction = model.predict(dim_array, verbose = 0)\n",
        "\n",
        "print(prediction)\n",
        "print(np.argmax(prediction[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfR-3zXtifNg",
        "colab_type": "text"
      },
      "source": [
        "# Save answers for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veLkTxzpUYCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if RETRAIN:\n",
        "    model= load_model(f\"{OUTPUT_FOLDER}CustomNet_{NBV}_retrained_best.hdf5\")\n",
        "\n",
        "else:\n",
        "    model= load_model(f\"{OUTPUT_FOLDER}CustomNet_{NBV}_best.hdf5\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b94QXZmyQ0mZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_dir= TEST_PATH\n",
        "\n",
        "\n",
        "with open(f\"/content/accent_detection/submission_format.csv\", mode='r') as submission_format:\n",
        "    csv_reader = csv.reader(submission_format, delimiter=',')\n",
        "\n",
        "    with open(f\"{OUTPUT_FOLDER}answers_{NBV}_.csv\", 'w', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile, delimiter=',',\n",
        "                                quotechar='|', quoting=csv.QUOTE_NONE)\n",
        "        \n",
        "        csv_writer.writerow([\"file_id\",\"accent\"]) # write header of answer file\n",
        "\n",
        "        for row in csv_reader:\n",
        "            if row[0] != \"file_id\": #skip reading the header row\n",
        "                file_path =os.path.join(test_dir,f\"{row[0]}.png\")\n",
        "\n",
        "                #print(f\"Processing file {file_path} ...\")\n",
        "                img = load_img(file_path, color_mode='grayscale', target_size=(img_height,img_width) )\n",
        "                img_array = img_to_array(img)\n",
        "\n",
        "                img_array = img_array * (1./255) #scaling the data\n",
        "                dim_array= np.array([img_array]) #tranforming to 4D array required as input\n",
        "                \n",
        "                prediction = model.predict(dim_array, verbose = 0)\n",
        "\n",
        "                #print(\"Prediction for file {0} = {1}\".format(row[0],prediction[0]))\n",
        "                csv_writer.writerow([row[0], \"{0}\".format(np.argmax(prediction[0]))])\n",
        "\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YV-PbMvMRtM",
        "colab_type": "text"
      },
      "source": [
        "# Inspirational references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au3pi0DEXOG4",
        "colab_type": "text"
      },
      "source": [
        "https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1\n",
        "\n",
        "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
        "\n",
        "https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8\n",
        "\n",
        "https://software.intel.com/en-us/articles/hands-on-ai-part-14-image-data-preprocessing-and-augmentation\n",
        "\n",
        "Resnet: https://towardsdatascience.com/hitchhikers-guide-to-residual-networks-resnet-in-keras-385ec01ec8ff\n",
        "\n",
        "### Troubleshooting\n",
        "https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2016/10/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4x6LkyqhUsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
